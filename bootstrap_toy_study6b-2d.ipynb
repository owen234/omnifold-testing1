{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e1be84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"1\"\n",
    "\n",
    "\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "\n",
    "import omnifold6b as of\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a708ce4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  numpy version:  1.21.5\n",
      "  tensorflow version:  2.11.0\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\")\n",
    "print(\"  numpy version:  %s\" % str(np.version.version) )\n",
    "print(\"  tensorflow version:  %s\" % str(tf.__version__))\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53506acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcd5a27a",
   "metadata": {},
   "source": [
    "## Set model and resolution parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac997067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " Train covariance:\n",
      "   0,  0 : diagonal    1.0000\n",
      "   0,  1 :              1.000 *    1.500 *   -0.600 =  -0.9000\n",
      "   1,  1 : diagonal    2.2500\n",
      "\n",
      "\n",
      "\n",
      " True covariance:\n",
      "   0,  0 : diagonal    0.8100\n",
      "   0,  1 :              0.900 *    1.300 *   -0.600 =  -0.7020\n",
      "   1,  1 : diagonal    1.6900\n"
     ]
    }
   ],
   "source": [
    "ndim = 2\n",
    "\n",
    "##-------------\n",
    "\n",
    "train_mu = [ 0.0, 1.0 ]\n",
    "\n",
    "\n",
    "\n",
    "train_rho = [ [-0.6] ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_sig = [ 1.0, 1.5 ]\n",
    "\n",
    "\n",
    "##-------------\n",
    "\n",
    "\n",
    "true_mu = [ 0.2, 0.8 ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "true_rho  = [ [-0.6] ]\n",
    "\n",
    "\n",
    "\n",
    "true_sig = [ 0.9, 1.3 ]\n",
    "\n",
    "\n",
    "\n",
    "#--- nominal\n",
    "resolution = [ 0.5, 0.8  ]\n",
    "\n",
    "#--- poor\n",
    "#resolution = [ 1.0, 1.6  ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_cov = np.zeros( shape=(ndim,ndim) )\n",
    "true_cov  = np.zeros( shape=(ndim,ndim) )\n",
    "\n",
    "print(\"\\n\\n\\n Train covariance:\")\n",
    "\n",
    "for i in range(ndim) :\n",
    "    for j in range(ndim) :\n",
    "        if j < i : continue\n",
    "        if i == j :\n",
    "            train_cov[i][j] = train_sig[i] * train_sig[j]\n",
    "            print(\"  %2d, %2d : diagonal  %8.4f\" % (i,j, train_cov[i][j]))\n",
    "        else :\n",
    "            k = ndim - j - 1\n",
    "            train_cov[i][j] = train_sig[i] * train_sig[j] * train_rho[i][k]\n",
    "            train_cov[j][i] = train_cov[i][j]\n",
    "            print(\"  %2d, %2d :           %8.3f * %8.3f * %8.3f = %8.4f\" % \n",
    "                  (i,j, train_sig[i], train_sig[j], train_rho[i][k], train_cov[i][j]))\n",
    "            \n",
    "            \n",
    "\n",
    "print(\"\\n\\n\\n True covariance:\")  \n",
    "\n",
    "for i in range(ndim) :\n",
    "    for j in range(ndim) :\n",
    "        if j < i : continue\n",
    "        if i == j :\n",
    "            true_cov[i][j] = true_sig[i] * true_sig[j]\n",
    "            print(\"  %2d, %2d : diagonal  %8.4f\" % (i,j, true_cov[i][j]))\n",
    "        else :\n",
    "            k = ndim - j - 1\n",
    "            true_cov[i][j] = true_sig[i] * true_sig[j] * true_rho[i][k]\n",
    "            true_cov[j][i] = true_cov[i][j]\n",
    "            print(\"  %2d, %2d :           %8.3f * %8.3f * %8.3f = %8.4f\" % \n",
    "                  (i,j, true_sig[i], true_sig[j], true_rho[i][k], true_cov[i][j]))\n",
    "            \n",
    "            \n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "ngen_train = 4000000\n",
    "ngen_true =  400000\n",
    "\n",
    "\n",
    "\n",
    "of_niter = 5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "learning_rate_setval = 0.0005\n",
    "\n",
    "\n",
    "epochs_setval = 40\n",
    "\n",
    "batch_size_setval = int( ngen_true )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_boot_samples = 100\n",
    "\n",
    "do_bootstrap = True\n",
    "\n",
    "\n",
    "output_dir = 'output-files-bootstrap-test6b-2d'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af5fdc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir( output_dir )\n",
    "except:\n",
    "    print('\\n\\n Output directory already exists:  %s' % output_dir)\n",
    "    print('\\n\\n HALTING EXECUTION\\n\\n')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63032edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( '%s/config-pars.npy' % output_dir , 'wb' ) as f :\n",
    "    np.save( f, train_mu )\n",
    "    np.save( f, train_rho )\n",
    "    np.save( f, train_sig )\n",
    "    np.save( f, true_mu )\n",
    "    np.save( f, true_rho )\n",
    "    np.save( f, true_sig )\n",
    "    np.save( f, resolution )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "159adca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  Config file contents : output-files-bootstrap-test6b-2d/config.txt\n",
      "\n",
      "2023-12-14 16:20:25.015690\n",
      "\n",
      "ngen_train 4000000\n",
      "ngen_true  400000\n",
      "of_niter   5\n",
      "ndim       2\n",
      "learning_rate_setval  0.000500\n",
      "epochs_setval  40\n",
      "batch_size_setval  400000\n",
      "n_boot_samples  100\n",
      "do_bootstrap  1\n",
      "\n",
      "\n",
      "train_mu : [0.0, 1.0]\n",
      "train_rho : [[-0.6]]\n",
      "train_sig : [1.0, 1.5]\n",
      "\n",
      "\n",
      "true_mu : [0.2, 0.8]\n",
      "true_rho : [[-0.6]]\n",
      "true_sig : [0.9, 1.3]\n",
      "\n",
      "\n",
      "resolution : [0.5, 0.8]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_filename = '%s/config.txt' % output_dir\n",
    "\n",
    "config_file = open( config_filename, 'w' )\n",
    "\n",
    "config_file.write('%s\\n\\n' % datetime.now() )\n",
    "config_file.write('ngen_train %d\\n' % ngen_train )\n",
    "config_file.write('ngen_true  %d\\n' % ngen_true )\n",
    "config_file.write('of_niter   %d\\n' % of_niter )\n",
    "config_file.write('ndim       %d\\n' % ndim )\n",
    "config_file.write('learning_rate_setval  %f\\n' % learning_rate_setval )\n",
    "config_file.write('epochs_setval  %d\\n' % epochs_setval )\n",
    "config_file.write('batch_size_setval  %d\\n' % batch_size_setval )\n",
    "config_file.write('n_boot_samples  %d\\n' % n_boot_samples )\n",
    "config_file.write('do_bootstrap  %d\\n' % do_bootstrap )\n",
    "config_file.write('\\n\\n')\n",
    "config_file.write('train_mu : %s\\n' % str(train_mu))\n",
    "config_file.write('train_rho : %s\\n' % str(train_rho))\n",
    "config_file.write('train_sig : %s\\n' % str(train_sig))\n",
    "config_file.write('\\n\\n')\n",
    "config_file.write('true_mu : %s\\n' % str(true_mu))\n",
    "config_file.write('true_rho : %s\\n' % str(true_rho))\n",
    "config_file.write('true_sig : %s\\n' % str(true_sig))\n",
    "config_file.write('\\n\\n')\n",
    "config_file.write('resolution : %s\\n' % str(resolution) )\n",
    "config_file.close()\n",
    "\n",
    "print('\\n\\n  Config file contents : %s\\n' % config_filename )\n",
    "print( subprocess.getoutput('cat %s' % config_filename ))\n",
    "print('\\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab1c4cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_det = np.linalg.det( train_cov )\n",
    "true_det  = np.linalg.det( true_cov )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62fcfa9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Train covariance determinant:  1.440000\n",
      "True covariance determinant:   0.876096\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\")\n",
    "print(\"Train covariance determinant:  %f\" % train_det )\n",
    "print(\"True covariance determinant:   %f\" % true_det )\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0755427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_det < 0 :\n",
    "    print('\\n\\n negative determinant!')\n",
    "    print('\\n\\n HALTING EXECUTION\\n\\n')\n",
    "    sys.exit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6df080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if true_det < 0 :\n",
    "    print('\\n\\n negative determinant!')\n",
    "    print('\\n\\n HALTING EXECUTION\\n\\n')\n",
    "    sys.exit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65bba42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7196c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cov_inv = np.linalg.inv( train_cov )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7daeb19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cov_inv_test = np.matmul( train_cov, train_cov_inv )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e51b1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " Train covariance\n",
      "[[ 1.   -0.9 ]\n",
      " [-0.9   2.25]]\n",
      "\n",
      " Train covariance inverse\n",
      "[[1.5625     0.625     ]\n",
      " [0.625      0.69444444]]\n",
      "\n",
      " Train covariance inverse test\n",
      "[[ 1.00000000e+00 -3.82410153e-17]\n",
      " [-5.55111512e-17  1.00000000e+00]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\")\n",
    "print(\" Train covariance\")\n",
    "print( train_cov )\n",
    "print(\"\\n Train covariance inverse\")\n",
    "print( train_cov_inv )\n",
    "print(\"\\n Train covariance inverse test\")\n",
    "print(train_cov_inv_test)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "237a9062",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_cov_inv = np.linalg.inv( true_cov )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb1bb7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_cov_inv_test = np.matmul( true_cov, true_cov_inv )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57280df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " True covariance\n",
      "[[ 0.81  -0.702]\n",
      " [-0.702  1.69 ]]\n",
      "\n",
      " True covariance inverse\n",
      "[[1.92901235 0.80128205]\n",
      " [0.80128205 0.92455621]]\n",
      "\n",
      " True covariance inverse test\n",
      "[[ 1.00000000e+00  3.80221824e-17]\n",
      " [-5.90695584e-17  1.00000000e+00]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\")\n",
    "print(\" True covariance\")\n",
    "print( true_cov )\n",
    "print(\"\\n True covariance inverse\")\n",
    "print( true_cov_inv )\n",
    "print(\"\\n True covariance inverse test\")\n",
    "print(true_cov_inv_test)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4ca2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd7b4128",
   "metadata": {},
   "source": [
    "## Generate the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ff65ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_pts = np.random.multivariate_normal(train_mu, train_cov, size=ngen_train)\n",
    "true_pts = np.random.multivariate_normal(true_mu, true_cov, size=ngen_true)\n",
    "\n",
    "train_det_pts = np.random.normal( train_pts, resolution )\n",
    "\n",
    "true_det_pts = np.random.normal( true_pts, resolution )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8336adcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( '%s/train-and-true-samples.npy' % output_dir, 'wb') as f :\n",
    "    np.save(f, train_pts)\n",
    "    np.save(f, train_det_pts)\n",
    "    np.save(f, true_pts)\n",
    "    np.save(f, true_det_pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd0f6f8",
   "metadata": {},
   "source": [
    "## Plots to visualize these parameter choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6be2a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots( ndim, ndim, figsize=(ndim*5, ndim*5))\n",
    "\n",
    "\n",
    "hmin=-6\n",
    "hmax=6\n",
    "hbins=40\n",
    "\n",
    "for i in range(ndim) :\n",
    "    for j in range(ndim) :\n",
    "        if j < i : continue\n",
    "        ax[i][j].hist2d( train_pts[:,i], train_pts[:,j], bins=[hbins,hbins], range=([hmin,hmax],[hmin,hmax]))\n",
    "\n",
    "\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f6217c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots( ndim, ndim, figsize=(ndim*5, ndim*5))\n",
    "\n",
    "\n",
    "hmin=-6\n",
    "hmax=6\n",
    "hbins=40\n",
    "\n",
    "for i in range(ndim) :\n",
    "    for j in range(ndim) :\n",
    "        if j < i : continue\n",
    "        ax[i][j].hist2d( true_pts[:,i], true_pts[:,j], bins=[hbins,hbins], range=([hmin,hmax],[hmin,hmax]))\n",
    "\n",
    "\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b86044d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots( 1, ndim, figsize=(ndim*5,5))\n",
    "hmin=-6\n",
    "hmax=6\n",
    "hbins=40\n",
    "\n",
    "\n",
    "for i in range(ndim) :\n",
    "        k = i*3 + j\n",
    "        ax[i].hist( train_pts[:,i],bins=hbins, range=[hmin,hmax], density=True )\n",
    "        ax[i].hist( true_pts[:,i],bins=hbins, range=[hmin,hmax], density=True, alpha=0.5 )\n",
    "    \n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bb9c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec49b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4904e11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe6795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6f6cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cd4f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "163478c2",
   "metadata": {},
   "source": [
    "## Set up NN model for OmniFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c894f0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 16:20:27.181532: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-14 16:20:27.206715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-14 16:20:27.207011: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-14 16:20:27.210796: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-14 16:20:27.211040: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-14 16:20:27.211269: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-14 16:20:27.685130: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-14 16:20:27.685413: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-14 16:20:27.685647: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-14 16:20:27.685851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22263 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:61:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "inputs = Input((ndim, ))\n",
    "hidden_layer_1 = Dense(50, activation='relu')(inputs)\n",
    "hidden_layer_2 = Dense(50, activation='relu')(hidden_layer_1)\n",
    "hidden_layer_3 = Dense(50, activation='relu')(hidden_layer_2)\n",
    "outputs = Dense(1, activation='sigmoid')(hidden_layer_3)\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d008a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a90ab248",
   "metadata": {},
   "source": [
    "## Package the training data for OmniFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fdd2141",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_both = np.stack([train_pts, train_det_pts], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2044abbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3785505f",
   "metadata": {},
   "source": [
    "## Run OmniFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3d1d70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  ======== omnifold6b\n",
      "\n",
      "\n",
      "  shape of theta0_S : (4000000, 2)\n",
      "  shape of theta_unknown_S : (400000, 2)\n",
      "  shape of xvals_1 :  (4400000, 2)\n",
      "\n",
      "\n",
      "\n",
      "  shape of labels0 : (4000000,)\n",
      "  shape of labels_unknown : (400000,)\n",
      "  shape of yvals_1 :  (4400000,)\n",
      "\n",
      "\n",
      "\n",
      "  shape of theta0_G : (4000000, 2)\n",
      "  shape of xvals_2 :  (8000000, 2)\n",
      "  shape of yvals_2 :  (8000000,)\n",
      "\n",
      " batch size setval  400000\n",
      " learning rate setval  0.000500\n",
      " epochs setval  40\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ITERATION: 1\n",
      "\n",
      "   -- ITERATION 1  STEP 1\n",
      "\n",
      " weights_push at the beginning\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "             running pre-training, distinguish from self.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 16:20:31.422614: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-12-14 16:20:31.426821: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fb72f890c90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-14 16:20:31.426834: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-12-14 16:20:31.430763: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-14 16:20:31.529350: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 2s 8ms/step - loss: 0.6966 - accuracy: 0.5490\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6933 - accuracy: 0.3912\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6933 - accuracy: 0.3482\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4480\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4362\n",
      "             done pretraining.\n",
      "Epoch 1/80\n",
      "9/9 [==============================] - 1s 27ms/step - loss: 0.1258 - accuracy: 0.4144 - val_loss: 0.1256 - val_accuracy: 0.4232\n",
      "Epoch 2/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1254 - accuracy: 0.4059 - val_loss: 0.1254 - val_accuracy: 0.3659\n",
      "Epoch 3/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1252 - accuracy: 0.3434 - val_loss: 0.1252 - val_accuracy: 0.3153\n",
      "Epoch 4/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1250 - accuracy: 0.2974 - val_loss: 0.1251 - val_accuracy: 0.2809\n",
      "Epoch 5/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1249 - accuracy: 0.2785 - val_loss: 0.1250 - val_accuracy: 0.2793\n",
      "Epoch 6/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1248 - accuracy: 0.2814 - val_loss: 0.1250 - val_accuracy: 0.2831\n",
      "Epoch 7/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1248 - accuracy: 0.2825 - val_loss: 0.1249 - val_accuracy: 0.2810\n",
      "Epoch 8/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1247 - accuracy: 0.2797 - val_loss: 0.1248 - val_accuracy: 0.2805\n",
      "Epoch 9/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1247 - accuracy: 0.2814 - val_loss: 0.1248 - val_accuracy: 0.2837\n",
      "Epoch 10/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1246 - accuracy: 0.2833 - val_loss: 0.1248 - val_accuracy: 0.2801\n",
      "Epoch 11/80\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1246 - accuracy: 0.2766 - val_loss: 0.1247 - val_accuracy: 0.2739\n",
      "Epoch 12/80\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1246 - accuracy: 0.2746 - val_loss: 0.1247 - val_accuracy: 0.2731\n",
      "Epoch 13/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1245 - accuracy: 0.2705 - val_loss: 0.1247 - val_accuracy: 0.2686\n",
      "Epoch 14/80\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1245 - accuracy: 0.2673 - val_loss: 0.1247 - val_accuracy: 0.2681\n",
      "Epoch 15/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1245 - accuracy: 0.2666 - val_loss: 0.1247 - val_accuracy: 0.2649\n",
      "Epoch 16/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1245 - accuracy: 0.2647 - val_loss: 0.1247 - val_accuracy: 0.2647\n",
      "Epoch 17/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1245 - accuracy: 0.2622 - val_loss: 0.1247 - val_accuracy: 0.2622\n",
      "Epoch 18/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1245 - accuracy: 0.2622 - val_loss: 0.1246 - val_accuracy: 0.2602\n",
      "Epoch 19/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1245 - accuracy: 0.2604 - val_loss: 0.1246 - val_accuracy: 0.2615\n",
      "Epoch 20/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1245 - accuracy: 0.2595 - val_loss: 0.1246 - val_accuracy: 0.2571\n",
      "Epoch 21/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1245 - accuracy: 0.2578 - val_loss: 0.1246 - val_accuracy: 0.2614\n",
      "Epoch 22/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1245 - accuracy: 0.2601 - val_loss: 0.1246 - val_accuracy: 0.2574\n",
      "Epoch 23/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1245 - accuracy: 0.2566 - val_loss: 0.1246 - val_accuracy: 0.2604\n",
      "Epoch 24/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1245 - accuracy: 0.2599 - val_loss: 0.1246 - val_accuracy: 0.2572\n",
      "Epoch 25/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1245 - accuracy: 0.2585 - val_loss: 0.1246 - val_accuracy: 0.2592\n",
      "Epoch 26/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1245 - accuracy: 0.2570 - val_loss: 0.1246 - val_accuracy: 0.2589\n",
      "Epoch 27/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1245 - accuracy: 0.2587 - val_loss: 0.1246 - val_accuracy: 0.2568\n",
      "Epoch 28/80\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1245 - accuracy: 0.2578 - val_loss: 0.1246 - val_accuracy: 0.2575\n",
      "Epoch 29/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1245 - accuracy: 0.2554 - val_loss: 0.1246 - val_accuracy: 0.2594\n",
      "Epoch 30/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1245 - accuracy: 0.2586 - val_loss: 0.1246 - val_accuracy: 0.2569\n",
      "Epoch 31/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1245 - accuracy: 0.2575 - val_loss: 0.1246 - val_accuracy: 0.2561\n",
      "Epoch 32/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1245 - accuracy: 0.2554 - val_loss: 0.1246 - val_accuracy: 0.2582\n",
      "Epoch 33/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1245 - accuracy: 0.2583 - val_loss: 0.1246 - val_accuracy: 0.2551\n",
      "Epoch 34/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2564 - val_loss: 0.1246 - val_accuracy: 0.2597\n",
      "Epoch 35/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2575 - val_loss: 0.1246 - val_accuracy: 0.2566\n",
      "Epoch 36/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2588 - val_loss: 0.1246 - val_accuracy: 0.2563\n",
      "Epoch 37/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.2547 - val_loss: 0.1246 - val_accuracy: 0.2561\n",
      "Epoch 38/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.2554 - val_loss: 0.1246 - val_accuracy: 0.2584\n",
      "Epoch 39/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2578 - val_loss: 0.1246 - val_accuracy: 0.2555\n",
      "Epoch 40/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.2549 - val_loss: 0.1246 - val_accuracy: 0.2568\n",
      "Epoch 41/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2542 - val_loss: 0.1246 - val_accuracy: 0.2602\n",
      "Epoch 42/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2584 - val_loss: 0.1246 - val_accuracy: 0.2524\n",
      "Epoch 43/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2545 - val_loss: 0.1246 - val_accuracy: 0.2600\n",
      "Epoch 44/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2576 - val_loss: 0.1246 - val_accuracy: 0.2517\n",
      "Epoch 45/80\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1244 - accuracy: 0.2532 - val_loss: 0.1246 - val_accuracy: 0.2592\n",
      "Epoch 46/80\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1244 - accuracy: 0.2574 - val_loss: 0.1246 - val_accuracy: 0.2546\n",
      "Epoch 47/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.2573 - val_loss: 0.1246 - val_accuracy: 0.2551\n",
      "Epoch 48/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.2537 - val_loss: 0.1246 - val_accuracy: 0.2579\n",
      "Epoch 49/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.2565 - val_loss: 0.1246 - val_accuracy: 0.2542\n",
      "Epoch 50/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.2563 - val_loss: 0.1246 - val_accuracy: 0.2555\n",
      "Epoch 51/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.2557 - val_loss: 0.1246 - val_accuracy: 0.2544\n",
      "Epoch 52/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.2538 - val_loss: 0.1246 - val_accuracy: 0.2570\n",
      "Epoch 53/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.2562 - val_loss: 0.1246 - val_accuracy: 0.2532\n",
      "Epoch 54/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.2551 - val_loss: 0.1246 - val_accuracy: 0.2585\n",
      "Epoch 55/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.2561 - val_loss: 0.1246 - val_accuracy: 0.2538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/80\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1244 - accuracy: 0.2555 - val_loss: 0.1246 - val_accuracy: 0.2583\n",
      "Epoch 57/80\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1244 - accuracy: 0.2555 - val_loss: 0.1246 - val_accuracy: 0.2556\n",
      "Epoch 58/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.2561 - val_loss: 0.1246 - val_accuracy: 0.2554\n",
      "Epoch 59/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2554 - val_loss: 0.1246 - val_accuracy: 0.2574\n",
      "Epoch 60/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.2569 - val_loss: 0.1246 - val_accuracy: 0.2528\n",
      "Epoch 61/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2536 - val_loss: 0.1246 - val_accuracy: 0.2572\n",
      "Epoch 62/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2566 - val_loss: 0.1246 - val_accuracy: 0.2531\n",
      "Epoch 63/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.2564 - val_loss: 0.1246 - val_accuracy: 0.2565\n",
      "Epoch 64/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.2537 - val_loss: 0.1246 - val_accuracy: 0.2598\n",
      "Epoch 65/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2582 - val_loss: 0.1246 - val_accuracy: 0.2526\n",
      "Epoch 66/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2565 - val_loss: 0.1246 - val_accuracy: 0.2554\n",
      "Epoch 67/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2536 - val_loss: 0.1246 - val_accuracy: 0.2576\n",
      "Epoch 68/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.2551 - val_loss: 0.1246 - val_accuracy: 0.2556\n",
      "Epoch 69/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2546 - val_loss: 0.1246 - val_accuracy: 0.2574\n",
      "Epoch 70/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2567 - val_loss: 0.1246 - val_accuracy: 0.2566\n",
      "Epoch 71/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2564 - val_loss: 0.1246 - val_accuracy: 0.2515\n",
      "Epoch 72/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2533 - val_loss: 0.1246 - val_accuracy: 0.2582\n",
      "Epoch 73/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.2550 - val_loss: 0.1246 - val_accuracy: 0.2523\n",
      "Epoch 74/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2552 - val_loss: 0.1246 - val_accuracy: 0.2597\n",
      "Epoch 75/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2576 - val_loss: 0.1246 - val_accuracy: 0.2560\n",
      "Epoch 76/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2571 - val_loss: 0.1246 - val_accuracy: 0.2534\n",
      "Epoch 77/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2530 - val_loss: 0.1246 - val_accuracy: 0.2592\n",
      "Epoch 78/80\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1244 - accuracy: 0.2567 - val_loss: 0.1246 - val_accuracy: 0.2561\n",
      "Epoch 79/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2569 - val_loss: 0.1246 - val_accuracy: 0.2568\n",
      "Epoch 80/80\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.2548 - val_loss: 0.1246 - val_accuracy: 0.2563\n",
      "400/400 [==============================] - 0s 623us/step\n",
      "\n",
      "   -- ITERATION 1  STEP 2\n",
      "\n",
      "             running pre-training, distinguish from self.\n",
      "Epoch 1/5\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 0.7010 - accuracy: 0.5719\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.7001 - accuracy: 0.5775\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6994 - accuracy: 0.5827\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6987 - accuracy: 0.5876\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6982 - accuracy: 0.5920\n",
      "             done pretraining.\n",
      "Epoch 1/80\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.6876 - accuracy: 0.4215 - val_loss: 0.6875 - val_accuracy: 0.4197\n",
      "Epoch 2/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6874 - accuracy: 0.4177 - val_loss: 0.6873 - val_accuracy: 0.4151\n",
      "Epoch 3/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6872 - accuracy: 0.4132 - val_loss: 0.6872 - val_accuracy: 0.4108\n",
      "Epoch 4/80\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6871 - accuracy: 0.4093 - val_loss: 0.6870 - val_accuracy: 0.4072\n",
      "Epoch 5/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6870 - accuracy: 0.4061 - val_loss: 0.6870 - val_accuracy: 0.4043\n",
      "Epoch 6/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6869 - accuracy: 0.4034 - val_loss: 0.6869 - val_accuracy: 0.4020\n",
      "Epoch 7/80\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6868 - accuracy: 0.4014 - val_loss: 0.6869 - val_accuracy: 0.4002\n",
      "Epoch 8/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6868 - accuracy: 0.3998 - val_loss: 0.6868 - val_accuracy: 0.3988\n",
      "Epoch 9/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6868 - accuracy: 0.3986 - val_loss: 0.6868 - val_accuracy: 0.3977\n",
      "Epoch 10/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6868 - accuracy: 0.3976 - val_loss: 0.6868 - val_accuracy: 0.3968\n",
      "Epoch 11/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3969 - val_loss: 0.6868 - val_accuracy: 0.3962\n",
      "Epoch 12/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3962 - val_loss: 0.6868 - val_accuracy: 0.3956\n",
      "Epoch 13/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3958 - val_loss: 0.6868 - val_accuracy: 0.3953\n",
      "Epoch 14/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3956 - val_loss: 0.6868 - val_accuracy: 0.3951\n",
      "Epoch 15/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3954 - val_loss: 0.6868 - val_accuracy: 0.3949\n",
      "Epoch 16/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3952 - val_loss: 0.6868 - val_accuracy: 0.3948\n",
      "Epoch 17/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3951 - val_loss: 0.6868 - val_accuracy: 0.3947\n",
      "Epoch 18/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3950 - val_loss: 0.6868 - val_accuracy: 0.3947\n",
      "Epoch 19/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3950 - val_loss: 0.6868 - val_accuracy: 0.3947\n",
      "Epoch 20/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3949 - val_loss: 0.6868 - val_accuracy: 0.3946\n",
      "Epoch 21/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3949 - val_loss: 0.6868 - val_accuracy: 0.3947\n",
      "Epoch 22/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3950 - val_loss: 0.6868 - val_accuracy: 0.3947\n",
      "Epoch 23/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3949 - val_loss: 0.6868 - val_accuracy: 0.3946\n",
      "Epoch 24/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3949 - val_loss: 0.6868 - val_accuracy: 0.3947\n",
      "Epoch 25/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3950 - val_loss: 0.6868 - val_accuracy: 0.3948\n",
      "Epoch 26/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3950 - val_loss: 0.6868 - val_accuracy: 0.3948\n",
      "Epoch 27/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3950 - val_loss: 0.6868 - val_accuracy: 0.3948\n",
      "Epoch 28/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3951 - val_loss: 0.6868 - val_accuracy: 0.3949\n",
      "Epoch 29/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6867 - accuracy: 0.3951 - val_loss: 0.6868 - val_accuracy: 0.3948\n",
      "Epoch 30/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3951 - val_loss: 0.6868 - val_accuracy: 0.3949\n",
      "Epoch 31/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3951 - val_loss: 0.6868 - val_accuracy: 0.3949\n",
      "Epoch 32/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3952 - val_loss: 0.6868 - val_accuracy: 0.3949\n",
      "Epoch 33/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3953 - val_loss: 0.6868 - val_accuracy: 0.3950\n",
      "Epoch 34/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3953 - val_loss: 0.6868 - val_accuracy: 0.3950\n",
      "Epoch 35/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3953 - val_loss: 0.6868 - val_accuracy: 0.3950\n",
      "Epoch 36/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3953 - val_loss: 0.6868 - val_accuracy: 0.3951\n",
      "Epoch 37/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3953 - val_loss: 0.6868 - val_accuracy: 0.3950\n",
      "Epoch 38/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3953 - val_loss: 0.6868 - val_accuracy: 0.3951\n",
      "Epoch 39/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3954 - val_loss: 0.6868 - val_accuracy: 0.3951\n",
      "Epoch 40/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3954 - val_loss: 0.6868 - val_accuracy: 0.3951\n",
      "Epoch 41/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3955 - val_loss: 0.6868 - val_accuracy: 0.3952\n",
      "Epoch 42/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3955 - val_loss: 0.6868 - val_accuracy: 0.3952\n",
      "Epoch 43/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3955 - val_loss: 0.6868 - val_accuracy: 0.3952\n",
      "Epoch 44/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3955 - val_loss: 0.6867 - val_accuracy: 0.3952\n",
      "Epoch 45/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3955 - val_loss: 0.6867 - val_accuracy: 0.3952\n",
      "Epoch 46/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3955 - val_loss: 0.6867 - val_accuracy: 0.3952\n",
      "Epoch 47/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3956 - val_loss: 0.6867 - val_accuracy: 0.3953\n",
      "Epoch 48/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3956 - val_loss: 0.6867 - val_accuracy: 0.3954\n",
      "Epoch 49/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3957 - val_loss: 0.6867 - val_accuracy: 0.3954\n",
      "Epoch 50/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3956 - val_loss: 0.6867 - val_accuracy: 0.3952\n",
      "Epoch 51/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3955 - val_loss: 0.6867 - val_accuracy: 0.3952\n",
      "Epoch 52/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3956 - val_loss: 0.6867 - val_accuracy: 0.3953\n",
      "Epoch 53/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3956 - val_loss: 0.6867 - val_accuracy: 0.3953\n",
      "Epoch 54/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3956 - val_loss: 0.6867 - val_accuracy: 0.3953\n",
      "Epoch 55/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3957 - val_loss: 0.6867 - val_accuracy: 0.3954\n",
      "Epoch 56/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3957 - val_loss: 0.6867 - val_accuracy: 0.3954\n",
      "Epoch 57/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3956 - val_loss: 0.6867 - val_accuracy: 0.3953\n",
      "Epoch 58/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3956 - val_loss: 0.6867 - val_accuracy: 0.3953\n",
      "Epoch 59/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3957 - val_loss: 0.6867 - val_accuracy: 0.3954\n",
      "Epoch 60/80\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6867 - accuracy: 0.3958 - val_loss: 0.6867 - val_accuracy: 0.3954\n",
      "Epoch 61/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3957 - val_loss: 0.6867 - val_accuracy: 0.3953\n",
      "Epoch 62/80\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6867 - accuracy: 0.3956 - val_loss: 0.6867 - val_accuracy: 0.3953\n",
      "Epoch 63/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3957 - val_loss: 0.6867 - val_accuracy: 0.3954\n",
      "Epoch 64/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3957 - val_loss: 0.6867 - val_accuracy: 0.3954\n",
      "Epoch 65/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3957 - val_loss: 0.6867 - val_accuracy: 0.3954\n",
      "Epoch 66/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3957 - val_loss: 0.6867 - val_accuracy: 0.3955\n",
      "Epoch 67/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3958 - val_loss: 0.6867 - val_accuracy: 0.3954\n",
      "Epoch 68/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3957 - val_loss: 0.6867 - val_accuracy: 0.3954\n",
      "Epoch 69/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3957 - val_loss: 0.6867 - val_accuracy: 0.3954\n",
      "Epoch 70/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3958 - val_loss: 0.6867 - val_accuracy: 0.3954\n",
      "Epoch 71/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3956 - val_loss: 0.6867 - val_accuracy: 0.3953\n",
      "Epoch 72/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3958 - val_loss: 0.6867 - val_accuracy: 0.3955\n",
      "Epoch 73/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3957 - val_loss: 0.6867 - val_accuracy: 0.3953\n",
      "Epoch 74/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3957 - val_loss: 0.6867 - val_accuracy: 0.3954\n",
      "Epoch 75/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3957 - val_loss: 0.6867 - val_accuracy: 0.3954\n",
      "Epoch 76/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3956 - val_loss: 0.6867 - val_accuracy: 0.3953\n",
      "Epoch 77/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3957 - val_loss: 0.6867 - val_accuracy: 0.3954\n",
      "Epoch 78/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3958 - val_loss: 0.6867 - val_accuracy: 0.3955\n",
      "Epoch 79/80\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.3958 - val_loss: 0.6867 - val_accuracy: 0.3954\n",
      "Epoch 80/80\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.3956 - val_loss: 0.6867 - val_accuracy: 0.3953\n",
      "400/400 [==============================] - 0s 577us/step\n",
      "\n",
      " +++ Saving step 2, iteration 0 model in output-files-bootstrap-test6b-2d/of-step2-iter00-model\n",
      "INFO:tensorflow:Assets written to: output-files-bootstrap-test6b-2d/of-step2-iter00-model/assets\n",
      "\n",
      "ITERATION: 2\n",
      "\n",
      "   -- ITERATION 2  STEP 1\n",
      "\n",
      " weights_push at the beginning\n",
      "[1.01540399 1.18826509 0.89012301 ... 1.08072186 1.25172627 1.07127833]\n",
      "             running pre-training, distinguish from self.\n",
      "Epoch 1/5\n",
      "15/15 [==============================] - 1s 7ms/step - loss: 0.6972 - accuracy: 0.6058\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6939 - accuracy: 0.6144\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6934 - accuracy: 0.5928\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5580\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5197\n",
      "             done pretraining.\n",
      "Epoch 1/40\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.1260 - accuracy: 0.3103 - val_loss: 0.1260 - val_accuracy: 0.3723\n",
      "Epoch 2/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1260 - accuracy: 0.3889 - val_loss: 0.1259 - val_accuracy: 0.3904\n",
      "Epoch 3/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.3756 - val_loss: 0.1259 - val_accuracy: 0.3530\n",
      "Epoch 4/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.3430 - val_loss: 0.1259 - val_accuracy: 0.3270\n",
      "Epoch 5/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1259 - accuracy: 0.3178 - val_loss: 0.1259 - val_accuracy: 0.3081\n",
      "Epoch 6/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.3047 - val_loss: 0.1259 - val_accuracy: 0.3010\n",
      "Epoch 7/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1259 - accuracy: 0.2998 - val_loss: 0.1259 - val_accuracy: 0.2975\n",
      "Epoch 8/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.2976 - val_loss: 0.1258 - val_accuracy: 0.2951\n",
      "Epoch 9/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1259 - accuracy: 0.2923 - val_loss: 0.1258 - val_accuracy: 0.2872\n",
      "Epoch 10/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.2847 - val_loss: 0.1258 - val_accuracy: 0.2834\n",
      "Epoch 11/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.2845 - val_loss: 0.1258 - val_accuracy: 0.2836\n",
      "Epoch 12/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.2800 - val_loss: 0.1258 - val_accuracy: 0.2765\n",
      "Epoch 13/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.2765 - val_loss: 0.1258 - val_accuracy: 0.2774\n",
      "Epoch 14/40\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1259 - accuracy: 0.2776 - val_loss: 0.1258 - val_accuracy: 0.2762\n",
      "Epoch 15/40\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1259 - accuracy: 0.2751 - val_loss: 0.1258 - val_accuracy: 0.2734\n",
      "Epoch 16/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1259 - accuracy: 0.2731 - val_loss: 0.1258 - val_accuracy: 0.2741\n",
      "Epoch 17/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1259 - accuracy: 0.2754 - val_loss: 0.1258 - val_accuracy: 0.2752\n",
      "Epoch 18/40\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1259 - accuracy: 0.2719 - val_loss: 0.1258 - val_accuracy: 0.2695\n",
      "Epoch 19/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1259 - accuracy: 0.2699 - val_loss: 0.1258 - val_accuracy: 0.2712\n",
      "Epoch 20/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1259 - accuracy: 0.2712 - val_loss: 0.1258 - val_accuracy: 0.2698\n",
      "Epoch 21/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1259 - accuracy: 0.2689 - val_loss: 0.1258 - val_accuracy: 0.2686\n",
      "Epoch 22/40\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1259 - accuracy: 0.2690 - val_loss: 0.1258 - val_accuracy: 0.2682\n",
      "Epoch 23/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.2677 - val_loss: 0.1258 - val_accuracy: 0.2673\n",
      "Epoch 24/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1259 - accuracy: 0.2688 - val_loss: 0.1258 - val_accuracy: 0.2702\n",
      "Epoch 25/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.2714 - val_loss: 0.1258 - val_accuracy: 0.2693\n",
      "Epoch 26/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1259 - accuracy: 0.2659 - val_loss: 0.1258 - val_accuracy: 0.2646\n",
      "Epoch 27/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.2655 - val_loss: 0.1258 - val_accuracy: 0.2684\n",
      "Epoch 28/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1259 - accuracy: 0.2707 - val_loss: 0.1258 - val_accuracy: 0.2710\n",
      "Epoch 29/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.2703 - val_loss: 0.1258 - val_accuracy: 0.2681\n",
      "Epoch 30/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1259 - accuracy: 0.2665 - val_loss: 0.1258 - val_accuracy: 0.2655\n",
      "Epoch 31/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.2667 - val_loss: 0.1258 - val_accuracy: 0.2676\n",
      "Epoch 32/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.2688 - val_loss: 0.1258 - val_accuracy: 0.2694\n",
      "Epoch 33/40\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1259 - accuracy: 0.2679 - val_loss: 0.1258 - val_accuracy: 0.2654\n",
      "Epoch 34/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.2657 - val_loss: 0.1258 - val_accuracy: 0.2658\n",
      "Epoch 35/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.2672 - val_loss: 0.1258 - val_accuracy: 0.2658\n",
      "Epoch 36/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.2648 - val_loss: 0.1258 - val_accuracy: 0.2642\n",
      "Epoch 37/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.2625 - val_loss: 0.1258 - val_accuracy: 0.2635\n",
      "Epoch 38/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.2664 - val_loss: 0.1258 - val_accuracy: 0.2683\n",
      "Epoch 39/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.2665 - val_loss: 0.1258 - val_accuracy: 0.2660\n",
      "Epoch 40/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.2694 - val_loss: 0.1258 - val_accuracy: 0.2679\n",
      "400/400 [==============================] - 0s 591us/step\n",
      "\n",
      "   -- ITERATION 2  STEP 2\n",
      "\n",
      "             running pre-training, distinguish from self.\n",
      "Epoch 1/5\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 0.6938 - accuracy: 0.5793\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6937 - accuracy: 0.5969\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6936 - accuracy: 0.6074\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6936 - accuracy: 0.6109\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6935 - accuracy: 0.6117\n",
      "             done pretraining.\n",
      "Epoch 1/40\n",
      "15/15 [==============================] - 1s 19ms/step - loss: 0.6922 - accuracy: 0.2500 - val_loss: 0.6923 - val_accuracy: 0.2500\n",
      "Epoch 2/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6922 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2500\n",
      "Epoch 3/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 4/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 5/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 6/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 7/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.2499 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 8/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 9/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 10/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 11/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 12/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 14/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 15/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 16/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 17/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 18/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 19/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 20/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 21/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 22/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 23/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 24/40\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 25/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 26/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 27/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 28/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 29/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 30/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 31/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 32/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 33/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 34/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 35/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 36/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 37/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 38/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 39/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "Epoch 40/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.2500 - val_loss: 0.6922 - val_accuracy: 0.2501\n",
      "400/400 [==============================] - 0s 584us/step\n",
      "\n",
      " +++ Saving step 2, iteration 1 model in output-files-bootstrap-test6b-2d/of-step2-iter01-model\n",
      "INFO:tensorflow:Assets written to: output-files-bootstrap-test6b-2d/of-step2-iter01-model/assets\n",
      "\n",
      "ITERATION: 3\n",
      "\n",
      "   -- ITERATION 3  STEP 1\n",
      "\n",
      " weights_push at the beginning\n",
      "[1.00969463 1.2459963  0.88243283 ... 1.07847374 1.29192111 1.0647254 ]\n",
      "             running pre-training, distinguish from self.\n",
      "Epoch 1/5\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 0.6935 - accuracy: 0.5976\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5913\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5056\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.4817\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5001\n",
      "             done pretraining.\n",
      "Epoch 1/40\n",
      "9/9 [==============================] - 1s 47ms/step - loss: 0.1259 - accuracy: 0.2862 - val_loss: 0.1259 - val_accuracy: 0.3755\n",
      "Epoch 2/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.3840 - val_loss: 0.1259 - val_accuracy: 0.3731\n",
      "Epoch 3/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1259 - accuracy: 0.3468 - val_loss: 0.1259 - val_accuracy: 0.3040\n",
      "Epoch 4/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1259 - accuracy: 0.2861 - val_loss: 0.1259 - val_accuracy: 0.2749\n",
      "Epoch 5/40\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1259 - accuracy: 0.2797 - val_loss: 0.1259 - val_accuracy: 0.2867\n",
      "Epoch 6/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1259 - accuracy: 0.2814 - val_loss: 0.1259 - val_accuracy: 0.2774\n",
      "Epoch 7/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1259 - accuracy: 0.2748 - val_loss: 0.1259 - val_accuracy: 0.2693\n",
      "Epoch 8/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1259 - accuracy: 0.2643 - val_loss: 0.1259 - val_accuracy: 0.2615\n",
      "Epoch 9/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.2675 - val_loss: 0.1259 - val_accuracy: 0.2724\n",
      "Epoch 10/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2637 - val_loss: 0.1259 - val_accuracy: 0.2540\n",
      "Epoch 11/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2551 - val_loss: 0.1259 - val_accuracy: 0.2578\n",
      "Epoch 12/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2565 - val_loss: 0.1259 - val_accuracy: 0.2568\n",
      "Epoch 13/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2576 - val_loss: 0.1259 - val_accuracy: 0.2607\n",
      "Epoch 14/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2600 - val_loss: 0.1259 - val_accuracy: 0.2616\n",
      "Epoch 15/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2605 - val_loss: 0.1259 - val_accuracy: 0.2595\n",
      "Epoch 16/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2590 - val_loss: 0.1259 - val_accuracy: 0.2600\n",
      "Epoch 17/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2663 - val_loss: 0.1259 - val_accuracy: 0.2620\n",
      "Epoch 18/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2471 - val_loss: 0.1259 - val_accuracy: 0.2416\n",
      "Epoch 19/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2513 - val_loss: 0.1259 - val_accuracy: 0.2617\n",
      "Epoch 20/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2588 - val_loss: 0.1259 - val_accuracy: 0.2541\n",
      "Epoch 21/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2604 - val_loss: 0.1259 - val_accuracy: 0.2566\n",
      "Epoch 22/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.2457 - val_loss: 0.1259 - val_accuracy: 0.2402\n",
      "Epoch 23/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2507 - val_loss: 0.1259 - val_accuracy: 0.2591\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2496 - val_loss: 0.1259 - val_accuracy: 0.2475\n",
      "Epoch 25/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2556 - val_loss: 0.1259 - val_accuracy: 0.2543\n",
      "Epoch 26/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2451 - val_loss: 0.1259 - val_accuracy: 0.2406\n",
      "Epoch 27/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2490 - val_loss: 0.1259 - val_accuracy: 0.2493\n",
      "Epoch 28/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.2393 - val_loss: 0.1259 - val_accuracy: 0.2403\n",
      "Epoch 29/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2511 - val_loss: 0.1259 - val_accuracy: 0.2555\n",
      "Epoch 30/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2437 - val_loss: 0.1259 - val_accuracy: 0.2394\n",
      "Epoch 31/40\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1258 - accuracy: 0.2446 - val_loss: 0.1259 - val_accuracy: 0.2534\n",
      "Epoch 32/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.2521 - val_loss: 0.1259 - val_accuracy: 0.2486\n",
      "Epoch 33/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2445 - val_loss: 0.1259 - val_accuracy: 0.2473\n",
      "Epoch 34/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.2461 - val_loss: 0.1259 - val_accuracy: 0.2525\n",
      "Epoch 35/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2566 - val_loss: 0.1259 - val_accuracy: 0.2505\n",
      "Epoch 36/40\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1258 - accuracy: 0.2504 - val_loss: 0.1259 - val_accuracy: 0.2461\n",
      "Epoch 37/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.2464 - val_loss: 0.1259 - val_accuracy: 0.2450\n",
      "Epoch 38/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.2417 - val_loss: 0.1259 - val_accuracy: 0.2424\n",
      "Epoch 39/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.2500 - val_loss: 0.1259 - val_accuracy: 0.2482\n",
      "Epoch 40/40\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1258 - accuracy: 0.2413 - val_loss: 0.1259 - val_accuracy: 0.2379\n",
      "400/400 [==============================] - 0s 637us/step\n",
      "\n",
      "   -- ITERATION 3  STEP 2\n",
      "\n",
      "             running pre-training, distinguish from self.\n",
      "Epoch 1/5\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 0.6933 - accuracy: 0.6139\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6933 - accuracy: 0.6138\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6933 - accuracy: 0.6074\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6933 - accuracy: 0.6037\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6933 - accuracy: 0.6017\n",
      "             done pretraining.\n",
      "Epoch 1/40\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2501\n",
      "Epoch 2/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.2500 - val_loss: 0.6932 - val_accuracy: 0.2501\n",
      "Epoch 3/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2501\n",
      "Epoch 4/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.2500 - val_loss: 0.6932 - val_accuracy: 0.2501\n",
      "Epoch 5/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2500 - val_loss: 0.6932 - val_accuracy: 0.2501\n",
      "Epoch 6/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.2500 - val_loss: 0.6932 - val_accuracy: 0.2501\n",
      "Epoch 7/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2500 - val_loss: 0.6932 - val_accuracy: 0.2501\n",
      "Epoch 8/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2500 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 9/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 10/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 11/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 12/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 13/40\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 14/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 15/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 16/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 17/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.2500 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 18/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 19/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 20/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 21/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2503\n",
      "Epoch 22/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2503\n",
      "Epoch 23/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 24/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 25/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 26/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 27/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 28/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 29/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 30/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 31/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 32/40\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 33/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 34/40\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 35/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 36/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 38/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 39/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2502\n",
      "Epoch 40/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.2499 - val_loss: 0.6932 - val_accuracy: 0.2503\n",
      "400/400 [==============================] - 0s 597us/step\n",
      "\n",
      " +++ Saving step 2, iteration 2 model in output-files-bootstrap-test6b-2d/of-step2-iter02-model\n",
      "INFO:tensorflow:Assets written to: output-files-bootstrap-test6b-2d/of-step2-iter02-model/assets\n",
      "\n",
      "ITERATION: 4\n",
      "\n",
      "   -- ITERATION 4  STEP 1\n",
      "\n",
      " weights_push at the beginning\n",
      "[1.00421471 1.27048917 0.89218528 ... 1.06758436 1.30648512 1.04664111]\n",
      "             running pre-training, distinguish from self.\n",
      "Epoch 1/5\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 0.6933 - accuracy: 0.5940\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4875\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4606\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5051\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5287\n",
      "             done pretraining.\n",
      "Epoch 1/40\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.1261 - accuracy: 0.3156 - val_loss: 0.1263 - val_accuracy: 0.3491\n",
      "Epoch 2/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1261 - accuracy: 0.3677 - val_loss: 0.1263 - val_accuracy: 0.3803\n",
      "Epoch 3/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1261 - accuracy: 0.3567 - val_loss: 0.1263 - val_accuracy: 0.2980\n",
      "Epoch 4/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1261 - accuracy: 0.2841 - val_loss: 0.1263 - val_accuracy: 0.2789\n",
      "Epoch 5/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1261 - accuracy: 0.2801 - val_loss: 0.1263 - val_accuracy: 0.2717\n",
      "Epoch 6/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1261 - accuracy: 0.2660 - val_loss: 0.1263 - val_accuracy: 0.2695\n",
      "Epoch 7/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1261 - accuracy: 0.2756 - val_loss: 0.1263 - val_accuracy: 0.2667\n",
      "Epoch 8/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1261 - accuracy: 0.2706 - val_loss: 0.1263 - val_accuracy: 0.2640\n",
      "Epoch 9/40\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1261 - accuracy: 0.2611 - val_loss: 0.1263 - val_accuracy: 0.2603\n",
      "Epoch 10/40\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1261 - accuracy: 0.2600 - val_loss: 0.1263 - val_accuracy: 0.2685\n",
      "Epoch 11/40\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1261 - accuracy: 0.2620 - val_loss: 0.1263 - val_accuracy: 0.2661\n",
      "Epoch 12/40\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1261 - accuracy: 0.2697 - val_loss: 0.1263 - val_accuracy: 0.2689\n",
      "Epoch 13/40\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1261 - accuracy: 0.2678 - val_loss: 0.1263 - val_accuracy: 0.2607\n",
      "Epoch 14/40\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1261 - accuracy: 0.2690 - val_loss: 0.1263 - val_accuracy: 0.2688\n",
      "Epoch 15/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1261 - accuracy: 0.2606 - val_loss: 0.1263 - val_accuracy: 0.2550\n",
      "Epoch 16/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1261 - accuracy: 0.2618 - val_loss: 0.1263 - val_accuracy: 0.2655\n",
      "Epoch 17/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1261 - accuracy: 0.2573 - val_loss: 0.1263 - val_accuracy: 0.2568\n",
      "Epoch 18/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1261 - accuracy: 0.2532 - val_loss: 0.1263 - val_accuracy: 0.2699\n",
      "Epoch 19/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1261 - accuracy: 0.2742 - val_loss: 0.1263 - val_accuracy: 0.2575\n",
      "Epoch 20/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1261 - accuracy: 0.2511 - val_loss: 0.1263 - val_accuracy: 0.2517\n",
      "Epoch 21/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1261 - accuracy: 0.2554 - val_loss: 0.1263 - val_accuracy: 0.2641\n",
      "Epoch 22/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1261 - accuracy: 0.2607 - val_loss: 0.1263 - val_accuracy: 0.2642\n",
      "Epoch 23/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1261 - accuracy: 0.2624 - val_loss: 0.1263 - val_accuracy: 0.2523\n",
      "Epoch 24/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1261 - accuracy: 0.2583 - val_loss: 0.1263 - val_accuracy: 0.2657\n",
      "Epoch 25/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1261 - accuracy: 0.2584 - val_loss: 0.1263 - val_accuracy: 0.2616\n",
      "Epoch 26/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1261 - accuracy: 0.2545 - val_loss: 0.1263 - val_accuracy: 0.2649\n",
      "Epoch 27/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1261 - accuracy: 0.2737 - val_loss: 0.1263 - val_accuracy: 0.2662\n",
      "Epoch 28/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1261 - accuracy: 0.2599 - val_loss: 0.1263 - val_accuracy: 0.2531\n",
      "Epoch 29/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1261 - accuracy: 0.2738 - val_loss: 0.1263 - val_accuracy: 0.2729\n",
      "Epoch 30/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1261 - accuracy: 0.2532 - val_loss: 0.1263 - val_accuracy: 0.2555\n",
      "Epoch 31/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1261 - accuracy: 0.2834 - val_loss: 0.1263 - val_accuracy: 0.2533\n",
      "Epoch 32/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1261 - accuracy: 0.2317 - val_loss: 0.1263 - val_accuracy: 0.2572\n",
      "Epoch 33/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1261 - accuracy: 0.2670 - val_loss: 0.1263 - val_accuracy: 0.2619\n",
      "Epoch 34/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1261 - accuracy: 0.2535 - val_loss: 0.1263 - val_accuracy: 0.2637\n",
      "Epoch 35/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1261 - accuracy: 0.2673 - val_loss: 0.1263 - val_accuracy: 0.2558\n",
      "Epoch 36/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1261 - accuracy: 0.2488 - val_loss: 0.1263 - val_accuracy: 0.2678\n",
      "Epoch 37/40\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1261 - accuracy: 0.2618 - val_loss: 0.1263 - val_accuracy: 0.2574\n",
      "Epoch 38/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1261 - accuracy: 0.2603 - val_loss: 0.1263 - val_accuracy: 0.2801\n",
      "Epoch 39/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1261 - accuracy: 0.2753 - val_loss: 0.1263 - val_accuracy: 0.2647\n",
      "Epoch 40/40\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1261 - accuracy: 0.2545 - val_loss: 0.1263 - val_accuracy: 0.2773\n",
      "400/400 [==============================] - 0s 586us/step\n",
      "\n",
      "   -- ITERATION 4  STEP 2\n",
      "\n",
      "             running pre-training, distinguish from self.\n",
      "Epoch 1/5\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 0.6932 - accuracy: 0.5795\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5910\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5866\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5782\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5913\n",
      "             done pretraining.\n",
      "Epoch 1/40\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.6925 - accuracy: 0.2501 - val_loss: 0.6924 - val_accuracy: 0.2498\n",
      "Epoch 2/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2502\n",
      "Epoch 3/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 5/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2501\n",
      "Epoch 6/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2501\n",
      "Epoch 7/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2502\n",
      "Epoch 8/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.2499 - val_loss: 0.6924 - val_accuracy: 0.2501\n",
      "Epoch 9/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2502\n",
      "Epoch 10/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.2499 - val_loss: 0.6924 - val_accuracy: 0.2501\n",
      "Epoch 11/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.2499 - val_loss: 0.6924 - val_accuracy: 0.2501\n",
      "Epoch 12/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2501\n",
      "Epoch 13/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2501\n",
      "Epoch 14/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2501\n",
      "Epoch 15/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2501\n",
      "Epoch 16/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.2499 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 17/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2501\n",
      "Epoch 18/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 19/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2501\n",
      "Epoch 20/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 21/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 22/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 23/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 24/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 25/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 26/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 27/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 28/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 29/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 30/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 31/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 32/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 33/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 34/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 35/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 36/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 37/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 38/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 39/40\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "Epoch 40/40\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.2500\n",
      "400/400 [==============================] - 0s 600us/step\n",
      "\n",
      " +++ Saving step 2, iteration 3 model in output-files-bootstrap-test6b-2d/of-step2-iter03-model\n",
      "INFO:tensorflow:Assets written to: output-files-bootstrap-test6b-2d/of-step2-iter03-model/assets\n",
      "\n",
      "ITERATION: 5\n",
      "\n",
      "   -- ITERATION 5  STEP 1\n",
      "\n",
      " weights_push at the beginning\n",
      "[0.99021185 1.28207253 0.89456937 ... 1.04827257 1.31585771 1.01918206]\n",
      "             running pre-training, distinguish from self.\n",
      "Epoch 1/5\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 0.6932 - accuracy: 0.5657\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.4853\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.4716\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.4977\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4688\n",
      "             done pretraining.\n",
      "Epoch 1/40\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.1258 - accuracy: 0.2980 - val_loss: 0.1257 - val_accuracy: 0.2159\n",
      "Epoch 2/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.1787 - val_loss: 0.1257 - val_accuracy: 0.1686\n",
      "Epoch 3/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.1920 - val_loss: 0.1257 - val_accuracy: 0.2164\n",
      "Epoch 4/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2200 - val_loss: 0.1257 - val_accuracy: 0.2087\n",
      "Epoch 5/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2021 - val_loss: 0.1257 - val_accuracy: 0.1986\n",
      "Epoch 6/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2176 - val_loss: 0.1257 - val_accuracy: 0.2313\n",
      "Epoch 7/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.2162 - val_loss: 0.1257 - val_accuracy: 0.2093\n",
      "Epoch 8/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2114 - val_loss: 0.1257 - val_accuracy: 0.2230\n",
      "Epoch 9/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.2159 - val_loss: 0.1257 - val_accuracy: 0.2257\n",
      "Epoch 10/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2417 - val_loss: 0.1257 - val_accuracy: 0.2330\n",
      "Epoch 11/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2180 - val_loss: 0.1257 - val_accuracy: 0.2104\n",
      "Epoch 12/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2198 - val_loss: 0.1257 - val_accuracy: 0.2261\n",
      "Epoch 13/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.2222 - val_loss: 0.1257 - val_accuracy: 0.2107\n",
      "Epoch 14/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.1966 - val_loss: 0.1257 - val_accuracy: 0.2149\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.2382 - val_loss: 0.1257 - val_accuracy: 0.2420\n",
      "Epoch 16/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.2171 - val_loss: 0.1257 - val_accuracy: 0.1975\n",
      "Epoch 17/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2135 - val_loss: 0.1257 - val_accuracy: 0.2335\n",
      "Epoch 18/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2295 - val_loss: 0.1257 - val_accuracy: 0.2098\n",
      "Epoch 19/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2224 - val_loss: 0.1257 - val_accuracy: 0.2228\n",
      "Epoch 20/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2086 - val_loss: 0.1257 - val_accuracy: 0.2200\n",
      "Epoch 21/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2463 - val_loss: 0.1257 - val_accuracy: 0.2283\n",
      "Epoch 22/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.2011 - val_loss: 0.1257 - val_accuracy: 0.2131\n",
      "Epoch 23/40\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1258 - accuracy: 0.2292 - val_loss: 0.1257 - val_accuracy: 0.2359\n",
      "Epoch 24/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.2242 - val_loss: 0.1257 - val_accuracy: 0.2074\n",
      "Epoch 25/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.2050 - val_loss: 0.1257 - val_accuracy: 0.2275\n",
      "Epoch 26/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2494 - val_loss: 0.1257 - val_accuracy: 0.2244\n",
      "Epoch 27/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.2065 - val_loss: 0.1257 - val_accuracy: 0.2110\n",
      "Epoch 28/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.2335 - val_loss: 0.1257 - val_accuracy: 0.2192\n",
      "Epoch 29/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.2045 - val_loss: 0.1257 - val_accuracy: 0.2059\n",
      "Epoch 30/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.2077 - val_loss: 0.1257 - val_accuracy: 0.2274\n",
      "Epoch 31/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2448 - val_loss: 0.1257 - val_accuracy: 0.2042\n",
      "Epoch 32/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.1932 - val_loss: 0.1257 - val_accuracy: 0.2229\n",
      "Epoch 33/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2324 - val_loss: 0.1257 - val_accuracy: 0.2059\n",
      "Epoch 34/40\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.2103 - val_loss: 0.1257 - val_accuracy: 0.2218\n",
      "Epoch 35/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2287 - val_loss: 0.1257 - val_accuracy: 0.2127\n",
      "Epoch 36/40\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.2014 - val_loss: 0.1257 - val_accuracy: 0.2253\n",
      "Epoch 37/40\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 0.1256 - accuracy: 0.2258"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "verbose = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "of_return_dict = of.omnifold6b( \n",
    "    train_both, true_det_pts, of_niter, model, verbose, \n",
    "    batch_size_setval, learning_rate_setval, epochs_setval,\n",
    "    True, output_dir )\n",
    "\n",
    "of_weights = of_return_dict[\"weights\"]\n",
    "\n",
    "mc_weight_sf = (1.*len(true_det_pts))/(1.*len(train_both))\n",
    "\n",
    "push_weights = of_return_dict[\"push_weights\"]\n",
    "push_weights_scaled = np.copy( push_weights )\n",
    "push_weights_scaled = mc_weight_sf * push_weights\n",
    "\n",
    "final_push_weights = of_return_dict[\"final_push_weights\"]\n",
    "final_push_weights_scaled = np.copy(final_push_weights)\n",
    "final_push_weights_scaled = mc_weight_sf * final_push_weights\n",
    "\n",
    "\n",
    "with open( '%s/omnifold-output-weights.npy' % output_dir, 'wb') as f :\n",
    "    np.save(f, final_push_weights_scaled)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f592ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f933b5d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots( of_niter, 2, figsize=(18,7*of_niter))\n",
    "\n",
    "for ofi in range(0,of_niter) :\n",
    "    \n",
    "    ax[ofi][0].plot( of_return_dict['train-hist-step1-iter%d' % ofi].history['loss']  )\n",
    "    ax[ofi][0].plot( of_return_dict['train-hist-step1-iter%d' % ofi].history['val_loss']  )\n",
    "\n",
    "    ax[ofi][1].plot( of_return_dict['train-hist-step2-iter%d' % ofi].history['loss']  )\n",
    "    ax[ofi][1].plot( of_return_dict['train-hist-step2-iter%d' % ofi].history['val_loss']  )\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b929a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faa89e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig,ax = plt.subplots( of_niter, ndim, figsize=(18,4*of_niter))\n",
    "\n",
    "hmin=-6\n",
    "hmax=6\n",
    "hbins=40\n",
    "\n",
    "hist_data_mc_ofweighted = np.zeros( shape=(of_niter,ndim,hbins))\n",
    "hist_data_truth         = np.zeros( shape=(of_niter,ndim,hbins))\n",
    "\n",
    "lfontsize = 17\n",
    "\n",
    "plt.subplots_adjust( hspace=0.30)\n",
    "plt.subplots_adjust( wspace=0.25)\n",
    "\n",
    "do_renorm = True\n",
    "\n",
    "\n",
    "for ofi in range(0,of_niter) :\n",
    "\n",
    "    if do_renorm :\n",
    "        \n",
    "        for di in range(ndim) :\n",
    "            \n",
    "            ax[ofi][di].hist( train_pts[:,di], bins=hbins, density=True, range=[hmin,hmax], label='train particle' )\n",
    "            hist_data_mc_ofweighted[ofi,di],_,_ = ax[ofi][di].hist( train_pts[:,di], weights=push_weights[ofi], bins=hbins, density=True, range=[hmin,hmax], label='OF weighted particle', alpha=0.5 )\n",
    "            hist_data_truth[ofi,di],_,_ =         ax[ofi][di].hist( true_pts[:,di], bins=hbins, density=True, range=[hmin,hmax], label='true particle', histtype='step', color='black' )\n",
    "\n",
    "\n",
    "    else :\n",
    "        \n",
    "        for di in range(ndim) :\n",
    "\n",
    "        \n",
    "            hist_data_mc_ofweighted[ofi,di],_,_ = ax[ofi][di].hist( train_pts[:,di], weights=push_weights_scaled[ofi], bins=hbins, range=[hmin,hmax], label='OF weighted particle', alpha=0.5 )\n",
    "            hist_data_truth[ofi,di],_,_ =         ax[ofi][di].hist( true_pts[:,di], bins=hbins, range=[hmin,hmax], label='true particle', histtype='step', color='black' )\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    #ax[ofi][0].legend(loc='best', fontsize=13)\n",
    "    #ax[ofi][1].legend(loc='best', fontsize=13)\n",
    "    \n",
    "    \n",
    "    ax[ofi][0].set_xlabel('Feature 0', fontsize=lfontsize )\n",
    "    \n",
    "    ax[ofi][1].set_xlabel('Feature 1', fontsize=lfontsize )\n",
    "    \n",
    "    ax[ofi][0].set_title('Iteration %d' % ofi, fontsize=lfontsize )\n",
    "\n",
    "\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9895c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9dd98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data_diff = hist_data_mc_ofweighted - hist_data_truth\n",
    "hist_data_diff2 = hist_data_diff * hist_data_diff\n",
    "\n",
    "hist_data_sum_diff2 = np.zeros( shape=(of_niter,ndim))\n",
    "\n",
    "for ofi in range( of_niter ) :\n",
    "    for di in range( ndim ) :\n",
    "        hist_data_sum_diff2[ofi,di] = np.sum( hist_data_diff2[ofi,di])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e846f6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots( 1, ndim, figsize=(18,5))\n",
    "\n",
    "for ofi in range(of_niter) :\n",
    "    for di in range( ndim ) :\n",
    "        ax[di].plot(hist_data_diff[ofi,di])\n",
    "\n",
    "    \n",
    "plt.show   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots( 1, ndim, figsize=(18,5))\n",
    "\n",
    "ofi = 0\n",
    "for di in range( ndim ) :\n",
    "    ax[di].plot(hist_data_diff[ofi,di])\n",
    "\n",
    "ofi = of_niter-1\n",
    "for di in range( ndim ) :\n",
    "    ax[di].plot(hist_data_diff[ofi,di])\n",
    "\n",
    "    \n",
    "plt.show  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a104583",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots( 1, 2, figsize=(18,5))\n",
    "ax[0].plot( hist_data_sum_diff2)\n",
    "ax[1].plot( hist_data_sum_diff2)\n",
    "ax[1].set_yscale('log')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cd2a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50099298",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots( of_niter, 4, figsize=(24,7*of_niter))\n",
    "\n",
    "hmin=-6\n",
    "hmax=6\n",
    "hbins=40\n",
    "\n",
    "lfontsize = 17\n",
    "\n",
    "plt.subplots_adjust( hspace=0.30)\n",
    "plt.subplots_adjust( wspace=0.25)\n",
    "\n",
    "for ofi in range(0,of_niter) :\n",
    "\n",
    "    ax[ofi][0].hist( of_weights[ofi,0,:], bins=hbins, range=[0.,1.5] )\n",
    "    ax[ofi][1].hist( of_weights[ofi,1,:], bins=hbins, range=[0.,1.5] )\n",
    "    ax[ofi][2].hist( push_weights[ofi,:], bins=hbins, range=[0.,4] )\n",
    "    ax[ofi][3].hist2d( of_weights[ofi,0,:], of_weights[ofi,1,:], bins=[hbins,hbins] )\n",
    "    \n",
    "    ax[ofi][0].set_xlabel( 'step 1 weight', fontsize=lfontsize )\n",
    "    \n",
    "    ax[ofi][1].set_xlabel( 'step 2 weight', fontsize=lfontsize )\n",
    "    \n",
    "    ax[ofi][3].set_xlabel( 'step 1 weight', fontsize=lfontsize )\n",
    "    ax[ofi][3].set_ylabel( 'step 2 weight', fontsize=lfontsize )\n",
    "    \n",
    "    ax[ofi][0].set_title('Iteration %d' % ofi, fontsize=lfontsize )\n",
    "    \n",
    "    \n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f0a201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c106f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots( 1, 2, figsize=(8*2,5))\n",
    "\n",
    "hbins=80\n",
    "\n",
    "ax[0].hist( final_push_weights_scaled, bins=hbins)\n",
    "ax[0].set_yscale('log')\n",
    "\n",
    "ax[1].hist( np.log10(final_push_weights_scaled), bins=hbins)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07d1578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e8272d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "fig,ax = plt.subplots( of_niter, ndim, figsize=(18,4*of_niter))\n",
    "\n",
    "hmin=-6\n",
    "hmax=6\n",
    "hbins=40\n",
    "\n",
    "det_hist_data_mc_ofweighted = np.zeros( shape=(of_niter,ndim,hbins))\n",
    "det_hist_data_truth         = np.zeros( shape=(of_niter,ndim,hbins))\n",
    "\n",
    "lfontsize = 17\n",
    "\n",
    "plt.subplots_adjust( hspace=0.30)\n",
    "plt.subplots_adjust( wspace=0.25)\n",
    "\n",
    "do_renorm = True\n",
    "\n",
    "\n",
    "for ofi in range(0,of_niter) :\n",
    "\n",
    "    if do_renorm :\n",
    "        \n",
    "        for di in range(ndim) :\n",
    "            \n",
    "            ax[ofi][di].hist( train_det_pts[:,di], bins=hbins, density=True, range=[hmin,hmax], label='train particle' )\n",
    "            det_hist_data_mc_ofweighted[ofi,di],_,_ = ax[ofi][di].hist( train_det_pts[:,di], weights=push_weights[ofi], bins=hbins, density=True, range=[hmin,hmax], label='OF weighted particle', alpha=0.5 )\n",
    "            det_hist_data_truth[ofi,di],_,_ =         ax[ofi][di].hist( true_det_pts[:,di], bins=hbins, density=True, range=[hmin,hmax], label='true particle', histtype='step', color='black' )\n",
    "\n",
    "\n",
    "    else :\n",
    "        \n",
    "        for di in range(ndim) :\n",
    "\n",
    "        \n",
    "            det_hist_data_mc_ofweighted[ofi,di],_,_ = ax[ofi][di].hist( train_det_pts[:,di], weights=push_weights_scaled[ofi], bins=hbins, range=[hmin,hmax], label='OF weighted particle', alpha=0.5 )\n",
    "            det_hist_data_truth[ofi,di],_,_ =         ax[ofi][di].hist( true_det_pts[:,di], bins=hbins, range=[hmin,hmax], label='true particle', histtype='step', color='black' )\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    #ax[ofi][0].legend(loc='best', fontsize=13)\n",
    "    #ax[ofi][1].legend(loc='best', fontsize=13)\n",
    "    \n",
    "    \n",
    "    ax[ofi][0].set_xlabel('Feature 0', fontsize=lfontsize )\n",
    "    \n",
    "    ax[ofi][1].set_xlabel('Feature 1', fontsize=lfontsize )\n",
    "    \n",
    "    ax[ofi][0].set_title('Iteration %d' % ofi, fontsize=lfontsize )\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebba2aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5667add",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_hist_data_diff = det_hist_data_mc_ofweighted - det_hist_data_truth\n",
    "det_hist_data_diff2 = det_hist_data_diff * det_hist_data_diff\n",
    "\n",
    "det_hist_data_sum_diff2 = np.zeros( shape=(of_niter,ndim))\n",
    "\n",
    "for ofi in range( of_niter ) :\n",
    "    for di in range( ndim ) :\n",
    "        det_hist_data_sum_diff2[ofi,di] = np.sum( det_hist_data_diff2[ofi,di])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62516e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots( 1, ndim, figsize=(18,5))\n",
    "\n",
    "for ofi in range(of_niter) :\n",
    "    for di in range( ndim ) :\n",
    "        ax[di].plot(det_hist_data_diff[ofi,di])\n",
    "\n",
    "    \n",
    "plt.show   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ef9bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots( 1, ndim, figsize=(18,5))\n",
    "\n",
    "ofi = 0\n",
    "for di in range( ndim ) :\n",
    "    ax[di].plot(det_hist_data_diff[ofi,di])\n",
    "\n",
    "ofi = of_niter-1\n",
    "for di in range( ndim ) :\n",
    "    ax[di].plot(det_hist_data_diff[ofi,di])\n",
    "\n",
    "    \n",
    "plt.show  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ebbb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots( 1, 2, figsize=(18,5))\n",
    "ax[0].plot( det_hist_data_sum_diff2)\n",
    "ax[1].plot( det_hist_data_sum_diff2)\n",
    "ax[1].set_yscale('log')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f2d85b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6f6281",
   "metadata": {},
   "outputs": [],
   "source": [
    "step1_mean = np.zeros( of_niter )\n",
    "step1_rms = np.zeros( of_niter )\n",
    "\n",
    "step2_mean = np.zeros( of_niter )\n",
    "step2_rms = np.zeros( of_niter )\n",
    "\n",
    "iter_val = np.zeros( of_niter )\n",
    "\n",
    "for ofi in range( of_niter ) :\n",
    "    \n",
    "    iter_val[ofi] = ofi\n",
    "    \n",
    "    step1_mean[ofi] = np.mean( of_weights[ofi,0,:] )\n",
    "    step1_rms[ofi] = np.sqrt( np.var( of_weights[ofi,0,:]))\n",
    "    \n",
    "    step2_mean[ofi] = np.mean( of_weights[ofi,1,:] )\n",
    "    step2_rms[ofi] = np.sqrt( np.var( of_weights[ofi,1,:]))\n",
    "    \n",
    "    print(\"  iter %2d : step 1 mean  %.3f  rms %.3f      step 2 mean  %.3f  rms %.3f\" % \n",
    "          (ofi, step1_mean[ofi], step1_rms[ofi], step2_mean[ofi], step2_rms[ofi]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83be5ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots( 1, 2, figsize=(18,7))\n",
    "\n",
    "ax[0].plot( iter_val, step1_mean )\n",
    "ax[0].plot( iter_val, step2_mean )\n",
    "ax[0].set_ylim( 0.80, 1.05)\n",
    "\n",
    "ax[1].plot( iter_val, step1_rms )\n",
    "ax[1].plot( iter_val, step2_rms )\n",
    "ax[1].set_ylim( 0, 1.1*np.max(step1_rms))\n",
    "\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03629c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc78318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22467c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e991c75a",
   "metadata": {},
   "source": [
    "## Do the bootstrap samples in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53b214",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "verbose = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b4fcaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "for bi in range(0,n_boot_samples) :\n",
    "    \n",
    "    if do_bootstrap :\n",
    "        print(\"\\n Creating bootstrap sample %3d\" % bi )\n",
    "        boot_true_det_pts = rng.choice( true_det_pts, size=len(true_det_pts) )\n",
    "        \n",
    "    else :\n",
    "        print(\"\\n Creating toy sample %3d\" % bi )\n",
    "        boot_true_pts = np.random.multivariate_normal(true_mu, true_cov, size=ngen_true)\n",
    "        boot_true_det_pts = np.random.normal( boot_true_pts, [res0, res1])\n",
    "        \n",
    "\n",
    "        \n",
    "    boot_of_return_dict = of.omnifold6b( \n",
    "        train_both, boot_true_det_pts, of_niter, model, verbose, \n",
    "        batch_size_setval, learning_rate_setval, epochs_setval )\n",
    "\n",
    "\n",
    "    mc_weight_sf = (1.*len(boot_true_det_pts))/(1.*len(train_both))\n",
    "\n",
    "\n",
    "\n",
    "    boot_final_push_weights = boot_of_return_dict[\"final_push_weights\"]\n",
    "    boot_final_push_weights_scaled = boot_final_push_weights\n",
    "    boot_final_push_weights_scaled = mc_weight_sf * boot_final_push_weights\n",
    "    \n",
    "    print(\"\\n\\n bootstrap %d final push weights scaled:\" % bi)\n",
    "    print( boot_final_push_weights_scaled )\n",
    "\n",
    "     \n",
    "    with open( '%s/bootstrap-weights-%03d.npy' % ( output_dir, bi ), 'wb' ) as f :\n",
    "        np.save( f, boot_final_push_weights_scaled )\n",
    "        \n",
    "    del boot_final_push_weights_scaled\n",
    "    del boot_of_return_dict\n",
    "    gc.collect()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d97e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791e2f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15d5066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
